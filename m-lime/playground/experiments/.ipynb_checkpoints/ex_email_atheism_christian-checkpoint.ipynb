{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "class_names = ['atheism', 'christian']\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
    "train_vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "test_vectors = vectorizer.transform(newsgroups_test.data)\n",
    "train_vectors = train_vectors.toarray()\n",
    "test_vectors = test_vectors.toarray()\n",
    "tokenizer = vectorizer.build_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_features = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the NLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'model__es_give_up_after_nepochs': [20]\n",
    "        , 'model__hidden_size': [100, 250, 500]\n",
    "        , 'model__num_layers': [1, 3, 5]\n",
    "    }\n",
    "\n",
    "comb_parameters = [{\n",
    "        'es_give_up_after_nepochs': 20\n",
    "        , 'hidden_size': 100\n",
    "        , 'num_layers': 2\n",
    "        , 'n_classification_labels': 2,\n",
    "    }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for parameter in comb_parameters:\n",
    "    model = NLS(\n",
    "        verbose=0\n",
    "        , es=True\n",
    "        , gpu=True\n",
    "        , scale_data=False\n",
    "        , varying_theta0=False\n",
    "        , fixed_theta0=True\n",
    "        , dataloader_workers=0\n",
    "        # , with_mean=False\n",
    "        , **parameter\n",
    "    ) \n",
    "    model.fit(x_train=train_vectors, y_train=newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = test_vectors\n",
    "pred = model.predict(test_vectors)\n",
    "print('F1 Score:', sklearn.metrics.f1_score(newsgroups_test.target, pred, average='binary'))\n",
    "print('Accuracy', sklearn.metrics.accuracy_score(newsgroups_test.target, pred, normalize=True, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining a Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 83\n",
    "# newsgroups_test.data[idx]\n",
    "print('Document id: %d' % idx)\n",
    "# print(model.predict(test_vectors))\n",
    "print('Probability(christian) =', model.predict_proba([test_vectors[idx]]))\n",
    "\n",
    "print('True class: %s' % class_names[newsgroups_test.target[idx]])\n",
    "print('True class number:',newsgroups_test.target[idx] )\n",
    "print('Text:')\n",
    "print(newsgroups_test.data[idx])\n",
    "x_explain = test_vectors[idx].reshape(1, -1)\n",
    "document_explain = newsgroups_test.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     idx = i\n",
    "# #     # newsgroups_test.data[idx]\n",
    "# #     print('Document id: %d' % idx)\n",
    "# #     # print(model.predict(test_vectors))\n",
    "# #     print('Probability(christian) =', model.predict_proba([test_vectors[idx]]))\n",
    "\n",
    "# #     print('True class: %s' % class_names[newsgroups_test.target[idx]])\n",
    "# #     print('True class number:',newsgroups_test.target[idx] )\n",
    "# #     print('Text:')\n",
    "#     print('*****************************')\n",
    "#     print('*****************************')\n",
    "#     print(newsgroups_test.data[idx])\n",
    "#     x_explain = test_vectors[idx].reshape(1, -1)\n",
    "#     document_explain = newsgroups_test.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating an Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_NLS = ExplainText(model, class_names=['atheism', 'christian'], names_features=names_features)\n",
    "# dict_exp = exp.get_text_explanation(x_explain, document=document_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_exp = exp_NLS.get_text_explanation(x_explain, document=document_explain, num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_betas(dict_exp):\n",
    "    fig, ax = plt.subplots()\n",
    "    width = 0.35 \n",
    "    ind = np.arange(len(dict_exp['words'][::-1]))\n",
    "    bar_pos = plt.barh(ind-width/2, dict_exp['betas_document'][::-1], width, label='Atheism')\n",
    "    plt.title('Atheism Class Feature Importance')\n",
    "    bar_neg = plt.barh(ind + width/2, dict_exp['betas_document_neg'][::-1], width, label='Christian')\n",
    "    plt.title('Atheism Christian Class Feature Importance')\n",
    "    ax.set_yticks(ind)\n",
    "    ax.set_yticklabels(dict_exp['words'][::-1])\n",
    "    ax.grid(True, axis='y')\n",
    "    leg = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_betas(dict_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exp = exp_NLS.explain_graphical(x_explain, document=document_explain, num_features=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_features[dict_exp['indices_words']], dict_exp['indices_words']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_html = exp_NLS.document_html(x_explain, document=document_explain, num_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = dict_exp['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "prohibitedWords = ['on', 'Random', 'Words']\n",
    "big_regex = re.compile('|'.join(map(re.escape, prohibitedWords)))\n",
    "# the_message = big_regex.sub(\"<replaced>\", 'this message contains Some really Random Words')\n",
    "text = re.sub(r\"\\b(%s)\\b\" % \"|\".join(words), replace, text)\n",
    "the_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(matched):\n",
    "    # Matched.group(0) is the word that was found\n",
    "    # Return the replacement\n",
    "    return \"REPLACEMENT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['a', 'an']\n",
    "text = 'A word here, an b a'\n",
    "text = re.sub(r\"\\b(%s)\\b\" % \"|\".join(words), replace, text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_html(x_explain, document, num_features=10, tokenizer=None):\n",
    "    exp = exp_NLS.get_text_explanation(x_explain, document, num_features=num_features)\n",
    "    if tokenizer is None:\n",
    "        return None\n",
    "    document_html = document\n",
    "    document_tokens = tokenizer(document)\n",
    "    \n",
    "    format_i = '<b style=\"background-color:Tomato;\">' \n",
    "    format_e = '</b>'\n",
    "    for words in exp['words']:\n",
    "        if words in document_tokens:\n",
    "            document_html = re.sub(r\"\\b(%s)\\b\" % \"|\".join(words), '{:}{:}{:}'.format(\n",
    "                format_i, words, format_e), document_html)\n",
    "#             document_html = re.sub(words , '{:}{:}{:}'.format(format_i, words, format_e) , document_html)\n",
    "#     for words in document_tokens:\n",
    "#         if words in exp['words']:\n",
    "#             document_html += '<b>{:}</b>'.format(words)\n",
    "#         else:\n",
    "#             document_html += words\n",
    "#         print(words)\n",
    "        \n",
    "    print('************************')\n",
    "    print(document_html)\n",
    "    return TextHTML(document_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextHTML:\n",
    "    def __init__(self, html):\n",
    "        self.html = html\n",
    "    def _repr_html_(self):\n",
    "        return self.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _segment_with_tokens(text, tokens):\n",
    "    \"\"\"Segment a string around the tokens created by a passed-in tokenizer\"\"\"\n",
    "    list_form = []\n",
    "    text_ptr = 0\n",
    "    for token in tokens:\n",
    "        inter_token_string = []\n",
    "        while not text[text_ptr:].startswith(token):\n",
    "            inter_token_string.append(text[text_ptr])\n",
    "            text_ptr += 1\n",
    "            if text_ptr >= len(text):\n",
    "                raise ValueError(\"Tokenization produced tokens that do not belong in string!\")\n",
    "        text_ptr += len(token)\n",
    "        if inter_token_string:\n",
    "            list_form.append(''.join(inter_token_string))\n",
    "        list_form.append(token)\n",
    "    if text_ptr < len(text):\n",
    "        list_form.append(text[text_ptr:])\n",
    "    return list_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = document_html(x_explain, document, num_features=10, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = SparseMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_1 = make_pipeline(vectorizer, sparse_matrix, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=class_names, random_state=65464)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(newsgroups_test.data[idx], c_1.predict_proba, num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exp = exp_NLS.explain_graphical(x_explain, document=document_explain, num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation from the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_atheism = newsgroups_train.target[indices_atheism]\n",
    "x_train = np.array(train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_atheism = np.where(newsgroups_train.target == 0)[0]\n",
    "x_train_atheism = x_train[indices_atheism]\n",
    "important_words = x_train_atheism[:, dict_exp['indices_all_words']]\n",
    "sum_atheism = np.sum(important_words, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_christian = np.where(newsgroups_train.target == 1)[0]\n",
    "x_train_christian = x_train[indices_christian]\n",
    "important_words_christian = x_train_christian[:, dict_exp['indices_all_words']]\n",
    "sum_christian = np.sum(important_words_christian, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10), dpi=200)\n",
    "ax.barh(names_features[dict_exp['indices_all_words']], sum_christian, label='christian')\n",
    "ax.barh(names_features[dict_exp['indices_all_words']], sum_atheism, label='atheism', alpha=0.5)\n",
    "leg = plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 15))\n",
    "y_p = np.arange(len(names_features[dict_exp['indices_all_words']]))\n",
    "vals = sum_atheism-sum_christian\n",
    "colors = ['green' if x > 0 else 'red' for x in vals]\n",
    "ax.barh(y_p, vals, color=colors)\n",
    "ax.set_yticks(y_p)\n",
    "ax.set_yticklabels(names_features[dict_exp['indices_all_words']])\n",
    "x_lim = ax.get_xlim()\n",
    "colors = ['tab:orange', 'tab:blue']\n",
    "for i, y_p_i in enumerate(y_p):\n",
    "    i_c = i%2\n",
    "    ax.plot(x_lim, [y_p_i]*2, c=colors[i_c])\n",
    "ax.set_xlim(x_lim)\n",
    "title = ax.set_title('Atheism - Christain (frequency words)')\n",
    "# leg = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing: headers, footers, quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian']\n",
    "newsgroups_train_clean = fetch_20newsgroups(subset='train'\n",
    "                                      , remove=('headers', 'footers', 'quotes')\n",
    "                                      , categories=categories)\n",
    "newsgroups_test_clean = fetch_20newsgroups(subset='test'\n",
    "                                     , remove=('headers', 'footers', 'quotes')\n",
    "                                     , categories=categories)\n",
    "class_names = ['atheism', 'christian']\n",
    "vectorizer_clean = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=True)  # ngram_range=(1, 2)\n",
    "train_vectors_clean = vectorizer_clean.fit_transform(newsgroups_train_clean.data)\n",
    "test_vectors_clean = vectorizer_clean.transform(newsgroups_test_clean.data)\n",
    "train_vectors_clean = train_vectors_clean.toarray()\n",
    "test_vectors_clean = test_vectors_clean.toarray()\n",
    "tokenizer_clean = vectorizer_clean.build_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_features_clean = np.array(vectorizer_clean.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer_clean.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the NLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_parameters = [{\n",
    "        'es_give_up_after_nepochs': 20\n",
    "        , 'hidden_size': 100\n",
    "        , 'num_layers': 2\n",
    "        , 'n_classification_labels': 2,\n",
    "    }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in comb_parameters:\n",
    "    model_clean = NLS(\n",
    "        verbose=0\n",
    "        , es=True\n",
    "        , gpu=True\n",
    "        , scale_data=False\n",
    "        , varying_theta0=False\n",
    "        , fixed_theta0=True\n",
    "        , dataloader_workers=0\n",
    "        # , with_mean=False\n",
    "        , **parameter\n",
    "    ) \n",
    "    model_clean.fit(x_train=train_vectors_clean, y_train=newsgroups_train_clean.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model_clean.predict(test_vectors_clean)\n",
    "pred_poba = model_clean.predict_proba(test_vectors_clean)\n",
    "print('Score:', sklearn.metrics.f1_score(newsgroups_test_clean.target, pred, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating an Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alterando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_NLS_clean = ExplainText(model_clean\n",
    "                             , class_names=['atheism', 'christian']\n",
    "                             , names_features=names_features_clean\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_exp_clean = exp_NLS_clean.get_text_explanation(x_explain_clean\n",
    "                                              , document=document_explain_clean\n",
    "                                              , num_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = model_clean.get_thetas(x_pred=x_explain_clean, net_scale=True)[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_explain_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_from_text_indices = np.argwhere(x_explain_clean[0] > 0).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_doc = names_features_clean[words_from_text_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_r = betas[words_from_text_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_sum = np.abs(betas_r[:, 0] - betas_r[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(betas_sum)[::-1]\n",
    "# names_doc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_betas(dict_exp_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exp = exp_NLS_clean.explain_graphical(x_explain_clean\n",
    "                                           , document=document_explain_clean\n",
    "                                           , num_features=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_features_clean[dict_exp_clean['indices_words']], dict_exp_clean['indices_words']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = SparseMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_clean = make_pipeline(vectorizer_clean, sparse_matrix, model_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer_clean = LimeTextExplainer(class_names=class_names, random_state=65464)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_clean = explainer_clean.explain_instance(newsgroups_test_clean.data[idx]\n",
    "                                             , c_1.predict_proba\n",
    "                                             , num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_clean.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_clean.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(train_vectors_clean, newsgroups_train_clean.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(test_vectors_clean)\n",
    "sklearn.metrics.f1_score(newsgroups_test_clean.target, pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(x_explain_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in comb_parameters:\n",
    "    model_1 = NNPredict(\n",
    "        verbose=1\n",
    "        , es=True\n",
    "        , gpu=True\n",
    "        , dataloader_workers=0\n",
    "        , **parameter\n",
    "    )\n",
    "    model_1.fit(x_train=train_vectors, y_train=newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_1.predict(test_vectors)\n",
    "print('Score:', sklearn.metrics.f1_score(newsgroups_test.target, pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = make_pipeline(vectorizer, sparse_matrix, model_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.predict_proba([newsgroups_test.data[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def label_bar(rects, ax, labels=None, offset_y=0.4):\n",
    "    colors = ['blue', 'orange']\n",
    "    N = len(rects)\n",
    "#     for rect, color in zip(rects, colors):\n",
    "    for i in range(N):\n",
    "        rect = rects[i]\n",
    "#         color = colors[i]\n",
    "        width = rect.get_width()\n",
    "        text_width = '{:3.2f}'.format(width)\n",
    "        if labels is None:\n",
    "            text = text_width\n",
    "            ax.annotate(text,\n",
    "                    xy=(rect.get_width() / 2, rect.get_y() - offset_y + rect.get_height() / 2),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\"\n",
    "                    , ha='center'\n",
    "                    , va='bottom',\n",
    "                    size=30)\n",
    "        else:\n",
    "            # alterando\n",
    "            text = labels[i]\n",
    "            ax.annotate(\n",
    "                text_width\n",
    "                , xy=(rect.get_width() / 2, (rect.get_y() + rect.get_height() / 2) - 0.25)\n",
    "                , xytext=(0, -1)  # 3 points vertical offset\n",
    "                , textcoords=\"offset points\"\n",
    "                , ha='center', va='bottom'\n",
    "                , size=13\n",
    "                , color='black'\n",
    "                , horizontalalignment='right'\n",
    "            )\n",
    "            if rect.get_width() > 0:\n",
    "                aling_text = 'right'\n",
    "                off_setx = -3\n",
    "            else:\n",
    "                aling_text = 'left'\n",
    "                off_setx = +3\n",
    "           \n",
    "            ax.annotate(\n",
    "                text\n",
    "                , xy=(rect.get_x(), rect.get_y())\n",
    "                , xytext=(off_setx, 0)  # 3 points vertical offset\n",
    "                , textcoords=\"offset points\"\n",
    "                , ha=aling_text\n",
    "                , va='bottom'\n",
    "                , size=14)\n",
    "#         print(rect.get_x(), rect.get_y(), rect.get_height(), rect.get_width())\n",
    "        \n",
    "     \n",
    "\n",
    "    \n",
    "def simpleaxis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "class SparseMatrix(object):\n",
    "    \"\"\"\n",
    "    Transformation to be used in a sklearn pipeline\n",
    "    check if a array is sparse.\n",
    "    # TODO: The NLS, LLS, NNPredict should accept sparse array\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self):\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def transform(x):\n",
    "        if issparse(x):\n",
    "            return x.toarray()\n",
    "        return x\n",
    "\n",
    "\n",
    "class ExplainText(object):\n",
    "    def __init__(self, model, class_names, names_features):\n",
    "        \"\"\"\n",
    "        :param model: NLS model;\n",
    "        :param class_names: class names to be utilized in the plot;\n",
    "        :param names_features: names of the features.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.class_names = np.array(class_names)\n",
    "        self.names_features = np.array(names_features)\n",
    "\n",
    "    def get_text_explanation(self, x_explain, document, num_features=10):\n",
    "        \"\"\"\n",
    "        Get the explanation of text document.\n",
    "        :param x_explain: document to be explained, should be vectorized;\n",
    "        :param document: document in text format;\n",
    "        :param num_features: number of features to produce the explanation.\n",
    "        :return: betas values and words correspondent to the explanation.\n",
    "        \"\"\"\n",
    "        explanation = self.model.get_thetas(x_pred=x_explain, net_scale=True)\n",
    "        betas = explanation[2][0]\n",
    "        words_from_text_indices = np.argwhere(x_explain[0] != 0).reshape(-1)\n",
    "                \n",
    "        # Prediction from the model\n",
    "        prediction = self.model.predict(x_explain).reshape(-1)\n",
    "        predict_proba = self.model.predict_proba(x_explain).reshape(-1)\n",
    "        ind_pred_proba = np.argsort(predict_proba)[::-1]\n",
    "\n",
    "        # Get the col_number of the predict and the second classes.\n",
    "        col_betas = ind_pred_proba[0]\n",
    "        col_betas_neg = ind_pred_proba[1]\n",
    "        \n",
    "        # Get the betas for the predict and second (neg) classes.\n",
    "        betas_document = betas[words_from_text_indices, col_betas]\n",
    "        betas_document_neg = betas[words_from_text_indices, col_betas_neg]\n",
    "\n",
    "        betas_final = betas_document - betas_document_neg\n",
    "        words_features_document = self.names_features[words_from_text_indices].reshape(-1)\n",
    "\n",
    "        # Ranking the betas by absolute value - crescent order.\n",
    "        beta_0_abs = np.abs(betas_final)\n",
    "        betas_rank_ind = np.argsort(beta_0_abs)[::-1]\n",
    "        # Selecting the first num_features important features.\n",
    "        betas_rank_ind = betas_rank_ind[:num_features] \n",
    "        \n",
    "        # Geting the important words.\n",
    "        words_features_document_rank = words_features_document[betas_rank_ind]\n",
    "\n",
    "        return dict(betas=betas_final[betas_rank_ind]\n",
    "                    , betas_document=betas_document[betas_rank_ind]\n",
    "                    , betas_document_neg=betas_document_neg[betas_rank_ind]\n",
    "                    , words=words_features_document_rank\n",
    "                    , prediction=prediction\n",
    "                    , prediction_proba=predict_proba\n",
    "                    , ind_class_sorted=ind_pred_proba\n",
    "                    , document=document\n",
    "                    , indices_words=words_from_text_indices[betas_rank_ind]\n",
    "                    , indices_all_words=words_from_text_indices\n",
    "                    )\n",
    "\n",
    "    def document_html(self, x_explain, document, num_features=10, tokenizer=None):\n",
    "        exp = self.get_text_explanation(x_explain, document, num_features=num_features)\n",
    "        if tokenizer is None:\n",
    "            return None\n",
    "        document_html = ''\n",
    "        document_tokens = tokenizer(document)\n",
    "        for words in document_tokens:\n",
    "            if words in exp['words']:\n",
    "                document_html += words\n",
    "            print(words)\n",
    "\n",
    "\n",
    "    def explain_graphical(self, x_explain, document, num_features=10):\n",
    "        exp = self.get_text_explanation(x_explain, document, num_features=num_features)\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 5), dpi=200)\n",
    "        colors = ['green', 'red']\n",
    "        rects1 = axs[0].barh(self.class_names[::-1], exp['prediction_proba'][::-1], color=colors[::-1])\n",
    "        axs[0].set_ylim([-3, 2])\n",
    "        simpleaxis(axs[0])\n",
    "        axs[0].set_xticks([])\n",
    "        axs[0].tick_params('y', labelsize=20)\n",
    "#         for rect, color in zip(rects1, colors):\n",
    "#             rect.set_color(color)\n",
    "        axs[0].set_title('Predicted Probabilities', size=20)\n",
    "        \n",
    "        label_bar(rects1, axs[0])\n",
    "        names = exp['words'][::-1]\n",
    "        vals = exp['betas'][::-1]\n",
    "        class_names_sorted = self.class_names[exp['ind_class_sorted']]\n",
    "        self.get_plot_feature_importance(axs[1], names, vals, class_names_sorted)\n",
    "        \n",
    "        \n",
    "        simpleaxis(axs[2])\n",
    "        axs[2].set_xticks([])\n",
    "        axs[2].set_yticks([])\n",
    "        axs[2].text(0, 1, '\\n' + exp['document'], style='italic', wrap=True, va='top')\n",
    "        axs[2].set_title('Document to Explain', size=20)\n",
    "        plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=None)\n",
    "        return fig, axs\n",
    "\n",
    "    def get_plot_feature_importance(self, ax, names, vals, class_names):\n",
    "        colors = ['green' if x > 0 else 'red' for x in vals]\n",
    "        pos = np.arange(len(vals))\n",
    "        rects2 = ax.barh(pos, vals, align='center', color=colors)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        label_bar(rects2, ax, labels=names)\n",
    "        ax.axvline(0, color='black', lw=2)\n",
    "        ax.set_title('Features Importance', size=20)\n",
    "        y_lim = np.array(ax.get_ylim())\n",
    "        ax.set_ylim(y_lim+np.array([0, 1.6]))\n",
    "        \n",
    "        ax.annotate('  ' + class_names[0], xy=(0,y_lim[1]), size=22, color='green', ha='left')\n",
    "        ax.annotate(class_names[1] + '  ', xy=(0,y_lim[1]), size=22, color='red', ha='right')\n",
    "        simpleaxis(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_NLS = ExplainText(model, class_names=['atheism', 'christian'], names_features=names_features)\n",
    "# dict_exp = exp.get_text_explanation(x_explain, document=document_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_exp = exp_NLS.get_text_explanation(x_explain, document=document_explain, num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exp = exp_NLS.explain_graphical(x_explain, document=document_explain, num_features=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
