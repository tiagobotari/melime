{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os, json, sys\n",
    "sys.path.append('../..') \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()   # interactive mode\n",
    "folder_data = '/media/tiago/tiagobotari/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "_image_size = 64\n",
    "_mean = [0.485, 0.456, 0.406]\n",
    "_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256*2),\n",
    "        transforms.RandomCrop(_image_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(.3, .3, .3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(_mean, _std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(_image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(_mean, _std)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ants = False\n",
    "if ants:\n",
    "    data_dir = '{:}/hymenoptera_data'.format(folder_data)\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                              data_transforms[x])\n",
    "                      for x in ['train', 'val']}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                                 shuffle=True, num_workers=4)\n",
    "                  for x in ['train', 'val']}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    class_names = image_datasets['train'].classes\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device\n",
    "\n",
    "    data_loader = dataloaders['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 144\n",
    "data_dir = '{:}/dogscats'.format(folder_data)\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "data_loader = dataloaders['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updateda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a batch of training data\n",
    "# inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# # Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "# print([class_names[x] for x in classes])\n",
    "# imshow(out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load MNIST Data\n",
    "# dataset = datasets.MNIST(root=folder_data, train=True, transform=transforms.ToTensor(), download=False)\n",
    "# data_loader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([144, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Fixed input for debugging\n",
    "fixed_x, _ = next(iter(data_loader))\n",
    "fixed_x = fixed_x.to(device)\n",
    "print(fixed_x.size())\n",
    "save_image(fixed_x, '../image.png')\n",
    "\n",
    "# Image('real_image.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(x, path='real_image.png'):\n",
    "    torchvision.utils.save_image(x, path)\n",
    "def flatten(x):\n",
    "    return to_var(x.view(x.size(0), -1))\n",
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "# from density_lime.densities.density_cvae import VAE\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_channels=3, kernel_size=3, stride=1, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.verbose = True\n",
    "#         self.nodes_dim = nodes_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.chanels = [32, 64, 128, 256, 512]\n",
    "        # Encoder\n",
    "        self.layers_encoder = nn.ModuleList(self.create_layers_encoder(image_channels=image_channels)) \n",
    "        \n",
    "        # Mu and log_var\n",
    "        in_linear_layer = self.chanels[-1]*4\n",
    "        self.fc_mu = nn.Linear(in_linear_layer, self.latent_dim)\n",
    "        self.fc_log_var = nn.Linear(in_linear_layer, self.latent_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear(self.latent_dim, in_linear_layer)\n",
    "        \n",
    "        # Decoder\n",
    "        self.layers_decoder = nn.ModuleList(\n",
    "            self.create_layers_decoder(\n",
    "                image_channels=image_channels\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x_in = x\n",
    "#         print('encode out size: ', x_in.size())\n",
    "        for layer in self.layers_encoder:\n",
    "            # TODO: doubt!! no functional here, not sure what is the best option\n",
    "            x_in = layer(x_in)\n",
    "#           \n",
    "#             print('##############################')\n",
    "#             print(layer)\n",
    "#             print('encode out size: ', x_in.size())\n",
    "        return x_in\n",
    "\n",
    "    def decode(self, z):\n",
    "        x_in = z\n",
    "#         print('decode out size: ', x_in.size())\n",
    "        for layer in self.layers_decoder:\n",
    "            # TODO: doubt!! no functional here, not sure what is the best option\n",
    "            x_in = layer(x_in)\n",
    "#             print('##############################')\n",
    "#             print(layer)\n",
    "#             print('decode out size: ', x_in.size())\n",
    "        return x_in\n",
    "            \n",
    "    @staticmethod\n",
    "    def reparameterize(mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_enconde = self.encode(x)\n",
    "        x_enconde = torch.flatten(x_enconde, start_dim=1)\n",
    "#         x_enconde = x_enconde.view(-1, self.nodes_dim)\n",
    "#         print(x_enconde.size())\n",
    "        mu, log_var = self.fc_mu(x_enconde), self.fc_log_var(x_enconde)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        z = self.fc_out(z)\n",
    "        z = z.view(-1, 512, 2, 2)\n",
    "        x_out = self.decode(z)\n",
    "#         print('------------------------------------------------------------')\n",
    "        return x_out, mu, log_var\n",
    "    \n",
    "    def create_layers_encoder(self, image_channels):\n",
    "        # TODO: Would be nice to have some options here.\n",
    "        # TODO: doubt!!! I choose to use the Elu layer here. not sure about this.\n",
    "        # TODO: I am thinking to put a batch normalization between the layers.\n",
    "        out_chanels = self.chanels\n",
    "        layers = list()\n",
    "        for out_chanel in out_chanels:\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                nn.Conv2d(image_channels, out_chanel, kernel_size=3, stride=2, padding=1)\n",
    "                , nn.BatchNorm2d(out_chanel)\n",
    "                , nn.LeakyReLU()   \n",
    "                )\n",
    "            )\n",
    "            image_channels = out_chanel\n",
    "        return layers\n",
    "    \n",
    "    def create_layers_decoder(self, image_channels):\n",
    "        # TODO: Would be nice to have some options here.\n",
    "        # TODO: doubt!!! I choose to use the Elu layer here. not sure about this.\n",
    "        # TODO: I am thinking to put a batch normalization between the layers.\n",
    "        out_chanels = self.chanels\n",
    "        out_chanels.reverse()\n",
    "        print(out_chanels)\n",
    "        print(out_chanels[:-1])\n",
    "        layers = list()\n",
    "        for in_chanel, out_chanel in zip(out_chanels[:-1], out_chanels[1:]) :\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                 nn.ConvTranspose2d(\n",
    "                     in_chanel, out_chanel, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "                , nn.BatchNorm2d(out_chanel)\n",
    "                , nn.LeakyReLU()   \n",
    "                )\n",
    "            )\n",
    "                \n",
    "        layers.append(\n",
    "            nn.Sequential(\n",
    "                            nn.ConvTranspose2d(out_chanels[-1],\n",
    "                                               out_chanels[-1],\n",
    "                                               kernel_size=3,\n",
    "                                               stride=2,\n",
    "                                               padding=1,\n",
    "                                               output_padding=1),\n",
    "                            nn.BatchNorm2d(out_chanels[-1]),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.Conv2d(out_chanels[-1], out_channels=3,\n",
    "                                      kernel_size=3, padding=1),\n",
    "                            nn.Sigmoid()\n",
    "            )\n",
    "        )\n",
    "        return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[512, 256, 128, 64, 32]\n",
      "[512, 256, 128, 64]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (layers_encoder): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc_log_var): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc_out): Linear(in_features=512, out_features=2048, bias=True)\n",
       "  (layers_decoder): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "image_channels = 3\n",
    "vae = VAE(image_channels=image_channels, latent_dim=256*2)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()\n",
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu**2 -  logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        for idx, (images, _) in enumerate(data_loader):\n",
    "            images = images.to(device)\n",
    "            recon_images, mu, logvar = vae(images)\n",
    "            loss = loss_fn(recon_images, images, mu, logvar)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx%100 == 0:\n",
    "                print(\"Epoch[{}/{}] Loss: {:.3f}\".format(epoch+1, epochs, loss.data.item()/batch_size))\n",
    "\n",
    "                recon_x, _, _ = vae(fixed_x)\n",
    "                save_image(recon_x.view(recon_x.size(0), image_channels, _image_size, _image_size).data.cpu(), f'{folder_data}/reco/i_{epoch}_{idx}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiago/anaconda3/envs/density-lime3.7/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/100] Loss: 9889.415\n",
      "Epoch[1/100] Loss: -193697.417\n",
      "Epoch[2/100] Loss: -177460.736\n",
      "Epoch[2/100] Loss: -208981.653\n",
      "Epoch[3/100] Loss: -206675.681\n",
      "Epoch[3/100] Loss: -221137.972\n",
      "Epoch[4/100] Loss: -260147.889\n",
      "Epoch[4/100] Loss: -244643.639\n",
      "Epoch[5/100] Loss: -274592.750\n",
      "Epoch[5/100] Loss: -259257.833\n",
      "Epoch[6/100] Loss: -255504.611\n",
      "Epoch[6/100] Loss: -265043.806\n",
      "Epoch[7/100] Loss: -237246.222\n",
      "Epoch[7/100] Loss: -262987.861\n",
      "Epoch[8/100] Loss: -263546.417\n",
      "Epoch[8/100] Loss: -273784.639\n",
      "Epoch[9/100] Loss: -244083.944\n",
      "Epoch[9/100] Loss: -257447.972\n",
      "Epoch[10/100] Loss: -240269.528\n",
      "Epoch[10/100] Loss: -275587.528\n",
      "Epoch[11/100] Loss: -274824.361\n",
      "Epoch[11/100] Loss: -256969.222\n",
      "Epoch[12/100] Loss: -252895.028\n",
      "Epoch[12/100] Loss: -261698.889\n",
      "Epoch[13/100] Loss: -245230.722\n",
      "Epoch[13/100] Loss: -295422.556\n",
      "Epoch[14/100] Loss: -257509.028\n",
      "Epoch[14/100] Loss: -294517.222\n",
      "Epoch[15/100] Loss: -282032.944\n",
      "Epoch[15/100] Loss: -307787.972\n",
      "Epoch[16/100] Loss: -273506.139\n",
      "Epoch[16/100] Loss: -262998.278\n",
      "Epoch[17/100] Loss: -271860.083\n",
      "Epoch[17/100] Loss: -313127.111\n",
      "Epoch[18/100] Loss: -262145.417\n",
      "Epoch[18/100] Loss: -285252.028\n",
      "Epoch[19/100] Loss: -275280.583\n",
      "Epoch[19/100] Loss: -291337.222\n",
      "Epoch[20/100] Loss: -275293.639\n",
      "Epoch[20/100] Loss: -285680.389\n",
      "Epoch[21/100] Loss: -296432.361\n",
      "Epoch[21/100] Loss: -305700.167\n",
      "Epoch[22/100] Loss: -296415.556\n",
      "Epoch[22/100] Loss: -302484.917\n",
      "Epoch[23/100] Loss: -299033.611\n",
      "Epoch[23/100] Loss: -289708.083\n",
      "Epoch[24/100] Loss: -295322.528\n",
      "Epoch[24/100] Loss: -285495.667\n",
      "Epoch[25/100] Loss: -302381.056\n",
      "Epoch[25/100] Loss: -324797.389\n",
      "Epoch[26/100] Loss: -316001.417\n",
      "Epoch[26/100] Loss: -329732.972\n",
      "Epoch[27/100] Loss: -297186.917\n",
      "Epoch[27/100] Loss: -317557.167\n",
      "Epoch[28/100] Loss: -338670.028\n",
      "Epoch[28/100] Loss: -304752.028\n",
      "Epoch[29/100] Loss: -323167.361\n",
      "Epoch[29/100] Loss: -327137.583\n",
      "Epoch[30/100] Loss: -310219.361\n",
      "Epoch[30/100] Loss: -331854.306\n",
      "Epoch[31/100] Loss: -291623.194\n",
      "Epoch[31/100] Loss: -326689.528\n",
      "Epoch[32/100] Loss: -314055.389\n",
      "Epoch[32/100] Loss: -336963.361\n",
      "Epoch[33/100] Loss: -278218.667\n",
      "Epoch[33/100] Loss: -312245.778\n",
      "Epoch[34/100] Loss: -329730.833\n",
      "Epoch[34/100] Loss: -327600.472\n",
      "Epoch[35/100] Loss: -262727.306\n",
      "Epoch[35/100] Loss: -325757.722\n",
      "Epoch[36/100] Loss: -307335.528\n",
      "Epoch[36/100] Loss: -340875.556\n",
      "Epoch[37/100] Loss: -323856.694\n",
      "Epoch[37/100] Loss: -352993.361\n",
      "Epoch[38/100] Loss: -320102.722\n",
      "Epoch[38/100] Loss: -385017.000\n",
      "Epoch[39/100] Loss: -311670.444\n",
      "Epoch[39/100] Loss: -325071.583\n",
      "Epoch[40/100] Loss: -329847.306\n",
      "Epoch[40/100] Loss: -313074.861\n",
      "Epoch[41/100] Loss: -335917.861\n",
      "Epoch[41/100] Loss: -363777.722\n",
      "Epoch[42/100] Loss: -333247.417\n",
      "Epoch[42/100] Loss: -327253.694\n",
      "Epoch[43/100] Loss: -367666.389\n",
      "Epoch[43/100] Loss: -335116.806\n",
      "Epoch[44/100] Loss: -337107.639\n",
      "Epoch[44/100] Loss: -350786.056\n",
      "Epoch[45/100] Loss: -368309.000\n",
      "Epoch[45/100] Loss: -330108.139\n",
      "Epoch[46/100] Loss: -309234.056\n",
      "Epoch[46/100] Loss: -384891.194\n",
      "Epoch[47/100] Loss: -333359.139\n",
      "Epoch[47/100] Loss: -349815.444\n",
      "Epoch[48/100] Loss: -355651.806\n",
      "Epoch[48/100] Loss: -336954.389\n",
      "Epoch[49/100] Loss: -377710.611\n",
      "Epoch[49/100] Loss: -339984.806\n",
      "Epoch[50/100] Loss: -325408.417\n",
      "Epoch[50/100] Loss: -363583.528\n",
      "Epoch[51/100] Loss: -349599.917\n",
      "Epoch[51/100] Loss: -334793.500\n",
      "Epoch[52/100] Loss: -333953.861\n",
      "Epoch[52/100] Loss: -375574.222\n",
      "Epoch[53/100] Loss: -364083.083\n",
      "Epoch[53/100] Loss: -348542.944\n",
      "Epoch[54/100] Loss: -358160.722\n",
      "Epoch[54/100] Loss: -348491.306\n",
      "Epoch[55/100] Loss: -353474.722\n",
      "Epoch[55/100] Loss: -319419.528\n",
      "Epoch[56/100] Loss: -323226.972\n",
      "Epoch[56/100] Loss: -335954.778\n",
      "Epoch[57/100] Loss: -359360.056\n",
      "Epoch[57/100] Loss: -345019.667\n",
      "Epoch[58/100] Loss: -365970.333\n",
      "Epoch[58/100] Loss: -330101.000\n",
      "Epoch[59/100] Loss: -346089.722\n",
      "Epoch[59/100] Loss: -349261.806\n",
      "Epoch[60/100] Loss: -366221.389\n",
      "Epoch[60/100] Loss: -360532.139\n",
      "Epoch[61/100] Loss: -365453.389\n",
      "Epoch[61/100] Loss: -372418.972\n",
      "Epoch[62/100] Loss: -366795.972\n",
      "Epoch[62/100] Loss: -368668.167\n",
      "Epoch[63/100] Loss: -338024.611\n",
      "Epoch[63/100] Loss: -393687.028\n",
      "Epoch[64/100] Loss: -365251.583\n",
      "Epoch[64/100] Loss: -323154.222\n",
      "Epoch[65/100] Loss: -391589.361\n",
      "Epoch[65/100] Loss: -369285.000\n",
      "Epoch[66/100] Loss: -362892.611\n",
      "Epoch[66/100] Loss: -381039.944\n",
      "Epoch[67/100] Loss: -348379.222\n",
      "Epoch[67/100] Loss: -381204.944\n",
      "Epoch[68/100] Loss: -361171.917\n",
      "Epoch[68/100] Loss: -375078.889\n",
      "Epoch[69/100] Loss: -359457.806\n",
      "Epoch[69/100] Loss: -359099.889\n",
      "Epoch[70/100] Loss: -415717.472\n",
      "Epoch[70/100] Loss: -361388.694\n",
      "Epoch[71/100] Loss: -366298.222\n",
      "Epoch[71/100] Loss: -343526.333\n",
      "Epoch[72/100] Loss: -395073.833\n",
      "Epoch[72/100] Loss: -348681.028\n",
      "Epoch[73/100] Loss: -371864.083\n",
      "Epoch[73/100] Loss: -427336.194\n",
      "Epoch[74/100] Loss: -365424.722\n",
      "Epoch[74/100] Loss: -365264.722\n",
      "Epoch[75/100] Loss: -368424.139\n",
      "Epoch[75/100] Loss: -388086.722\n",
      "Epoch[76/100] Loss: -368532.917\n",
      "Epoch[76/100] Loss: -383246.944\n",
      "Epoch[77/100] Loss: -381540.861\n",
      "Epoch[77/100] Loss: -369119.694\n",
      "Epoch[78/100] Loss: -415328.028\n",
      "Epoch[78/100] Loss: -386089.722\n",
      "Epoch[79/100] Loss: -372273.917\n",
      "Epoch[79/100] Loss: -333642.833\n",
      "Epoch[80/100] Loss: -383209.639\n",
      "Epoch[80/100] Loss: -345596.611\n",
      "Epoch[81/100] Loss: -317145.056\n",
      "Epoch[81/100] Loss: -386945.722\n",
      "Epoch[82/100] Loss: -410399.056\n",
      "Epoch[82/100] Loss: -427148.361\n",
      "Epoch[83/100] Loss: -315138.639\n",
      "Epoch[83/100] Loss: -446122.750\n",
      "Epoch[84/100] Loss: -399923.583\n",
      "Epoch[84/100] Loss: -416694.972\n",
      "Epoch[85/100] Loss: -422398.389\n",
      "Epoch[85/100] Loss: -338622.722\n",
      "Epoch[86/100] Loss: -365392.111\n",
      "Epoch[86/100] Loss: -398340.472\n",
      "Epoch[87/100] Loss: -355045.194\n",
      "Epoch[87/100] Loss: -385550.972\n",
      "Epoch[88/100] Loss: -387361.944\n",
      "Epoch[88/100] Loss: -383508.389\n",
      "Epoch[89/100] Loss: -394793.194\n",
      "Epoch[89/100] Loss: -332254.444\n",
      "Epoch[90/100] Loss: -409382.667\n",
      "Epoch[90/100] Loss: -379386.861\n",
      "Epoch[91/100] Loss: -345400.083\n",
      "Epoch[91/100] Loss: -359139.333\n",
      "Epoch[92/100] Loss: -383162.639\n",
      "Epoch[92/100] Loss: -396907.611\n",
      "Epoch[93/100] Loss: -308079.889\n",
      "Epoch[93/100] Loss: -265356.583\n",
      "Epoch[94/100] Loss: -360275.250\n",
      "Epoch[94/100] Loss: -387411.333\n",
      "Epoch[95/100] Loss: -288104.056\n",
      "Epoch[95/100] Loss: -316726.083\n",
      "Epoch[96/100] Loss: -252502.167\n",
      "Epoch[96/100] Loss: -262142.778\n",
      "Epoch[97/100] Loss: -318858.944\n",
      "Epoch[97/100] Loss: -359029.611\n",
      "Epoch[98/100] Loss: -318903.361\n",
      "Epoch[98/100] Loss: -274077.278\n",
      "Epoch[99/100] Loss: -285431.139\n",
      "Epoch[99/100] Loss: -338075.306\n",
      "Epoch[100/100] Loss: -297366.806\n",
      "Epoch[100/100] Loss: -286724.389\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 1.5\n",
      "CNN T 12\n"
     ]
    }
   ],
   "source": [
    "Hin = 5\n",
    "padding=1\n",
    "output_padding = 0\n",
    "dilation=1\n",
    "kernel_size=6\n",
    "stride=2 \n",
    "print('CNN', (Hin + 2*padding - dilation *(kernel_size-1)-1)/stride + 1)\n",
    "print('CNN T', (Hin-1)*stride - 2*padding+dilation*(kernel_size-1) + output_padding + 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/100] Loss: -300958.139\n",
      "Epoch[1/100] Loss: -240112.222\n",
      "Epoch[2/100] Loss: -330360.222\n",
      "Epoch[2/100] Loss: -301407.111\n",
      "Epoch[3/100] Loss: -324812.889\n",
      "Epoch[3/100] Loss: -290236.556\n",
      "Epoch[4/100] Loss: -335506.028\n",
      "Epoch[4/100] Loss: -312936.972\n",
      "Epoch[5/100] Loss: -415193.778\n",
      "Epoch[5/100] Loss: -356691.139\n",
      "Epoch[6/100] Loss: -264551.500\n",
      "Epoch[6/100] Loss: -371432.417\n",
      "Epoch[7/100] Loss: -249702.722\n",
      "Epoch[7/100] Loss: -275366.278\n",
      "Epoch[8/100] Loss: -235963.611\n",
      "Epoch[8/100] Loss: -275456.389\n",
      "Epoch[9/100] Loss: -297124.111\n",
      "Epoch[9/100] Loss: -367607.472\n",
      "Epoch[10/100] Loss: -288968.556\n",
      "Epoch[10/100] Loss: -291702.500\n",
      "Epoch[11/100] Loss: -339982.167\n",
      "Epoch[11/100] Loss: -245203.000\n",
      "Epoch[12/100] Loss: -256960.389\n",
      "Epoch[12/100] Loss: -342855.444\n",
      "Epoch[13/100] Loss: -286562.750\n",
      "Epoch[13/100] Loss: -304461.056\n",
      "Epoch[14/100] Loss: -305016.306\n",
      "Epoch[14/100] Loss: -332169.806\n",
      "Epoch[15/100] Loss: -336871.417\n",
      "Epoch[15/100] Loss: -264312.306\n",
      "Epoch[16/100] Loss: -276752.889\n",
      "Epoch[16/100] Loss: -292313.500\n",
      "Epoch[17/100] Loss: -203939.792\n",
      "Epoch[17/100] Loss: -253186.639\n",
      "Epoch[18/100] Loss: -233205.778\n",
      "Epoch[18/100] Loss: -334923.972\n",
      "Epoch[19/100] Loss: -236357.111\n",
      "Epoch[19/100] Loss: -253674.250\n",
      "Epoch[20/100] Loss: -297040.611\n",
      "Epoch[20/100] Loss: -319083.333\n",
      "Epoch[21/100] Loss: -211521.583\n",
      "Epoch[21/100] Loss: -219579.444\n",
      "Epoch[22/100] Loss: -283706.528\n",
      "Epoch[22/100] Loss: -252307.861\n",
      "Epoch[23/100] Loss: -210180.431\n",
      "Epoch[23/100] Loss: -322296.528\n",
      "Epoch[24/100] Loss: -242990.306\n",
      "Epoch[24/100] Loss: -255690.694\n",
      "Epoch[25/100] Loss: -254157.917\n",
      "Epoch[25/100] Loss: -253908.639\n",
      "Epoch[26/100] Loss: -302137.472\n",
      "Epoch[26/100] Loss: -253072.250\n",
      "Epoch[27/100] Loss: -318972.972\n",
      "Epoch[27/100] Loss: -264198.583\n",
      "Epoch[28/100] Loss: -297568.167\n",
      "Epoch[28/100] Loss: -257706.417\n",
      "Epoch[29/100] Loss: -232181.306\n",
      "Epoch[29/100] Loss: -267168.111\n",
      "Epoch[30/100] Loss: -225353.361\n",
      "Epoch[30/100] Loss: -322902.417\n",
      "Epoch[31/100] Loss: -255130.250\n",
      "Epoch[31/100] Loss: -320278.361\n",
      "Epoch[32/100] Loss: -300966.417\n",
      "Epoch[32/100] Loss: -267307.778\n",
      "Epoch[33/100] Loss: -264405.861\n",
      "Epoch[33/100] Loss: -215879.528\n",
      "Epoch[34/100] Loss: -181103.681\n",
      "Epoch[34/100] Loss: -241056.278\n",
      "Epoch[35/100] Loss: -222175.722\n",
      "Epoch[35/100] Loss: -269608.333\n",
      "Epoch[36/100] Loss: -316969.556\n",
      "Epoch[36/100] Loss: -319742.056\n",
      "Epoch[37/100] Loss: -281963.028\n",
      "Epoch[37/100] Loss: -235661.556\n",
      "Epoch[38/100] Loss: -315019.250\n",
      "Epoch[38/100] Loss: -237613.167\n",
      "Epoch[39/100] Loss: -349908.472\n",
      "Epoch[39/100] Loss: -258902.139\n",
      "Epoch[40/100] Loss: -280501.833\n",
      "Epoch[40/100] Loss: -287661.278\n",
      "Epoch[41/100] Loss: -223880.389\n",
      "Epoch[41/100] Loss: -250405.639\n",
      "Epoch[42/100] Loss: -272635.583\n",
      "Epoch[42/100] Loss: -253912.222\n",
      "Epoch[43/100] Loss: -262336.306\n",
      "Epoch[43/100] Loss: -277075.056\n",
      "Epoch[44/100] Loss: -201111.847\n",
      "Epoch[44/100] Loss: -250850.111\n",
      "Epoch[45/100] Loss: -328519.861\n",
      "Epoch[45/100] Loss: -275353.472\n",
      "Epoch[46/100] Loss: -270443.917\n",
      "Epoch[46/100] Loss: -238418.833\n",
      "Epoch[47/100] Loss: -242330.306\n",
      "Epoch[47/100] Loss: -217323.653\n",
      "Epoch[48/100] Loss: -221011.597\n",
      "Epoch[48/100] Loss: -237943.472\n",
      "Epoch[49/100] Loss: -245328.028\n",
      "Epoch[49/100] Loss: -226635.208\n",
      "Epoch[50/100] Loss: -318311.806\n",
      "Epoch[50/100] Loss: -286791.611\n",
      "Epoch[51/100] Loss: -234735.444\n",
      "Epoch[51/100] Loss: -253497.444\n",
      "Epoch[52/100] Loss: -230355.708\n",
      "Epoch[52/100] Loss: -234213.750\n",
      "Epoch[53/100] Loss: -215839.042\n",
      "Epoch[53/100] Loss: -262365.889\n",
      "Epoch[54/100] Loss: -245983.028\n",
      "Epoch[54/100] Loss: -263446.000\n",
      "Epoch[55/100] Loss: -285130.556\n",
      "Epoch[55/100] Loss: -306779.472\n",
      "Epoch[56/100] Loss: -315451.222\n",
      "Epoch[56/100] Loss: -256935.306\n",
      "Epoch[57/100] Loss: -278977.556\n",
      "Epoch[57/100] Loss: -308149.611\n",
      "Epoch[58/100] Loss: -231268.653\n",
      "Epoch[58/100] Loss: -222076.653\n",
      "Epoch[59/100] Loss: -236793.056\n",
      "Epoch[59/100] Loss: -251606.583\n",
      "Epoch[60/100] Loss: -278834.667\n",
      "Epoch[60/100] Loss: -233237.167\n",
      "Epoch[61/100] Loss: -220664.556\n",
      "Epoch[61/100] Loss: -243464.000\n",
      "Epoch[62/100] Loss: -282720.778\n",
      "Epoch[62/100] Loss: -197826.639\n",
      "Epoch[63/100] Loss: -237994.083\n",
      "Epoch[63/100] Loss: -227890.736\n",
      "Epoch[64/100] Loss: -317487.806\n",
      "Epoch[64/100] Loss: -221608.569\n",
      "Epoch[65/100] Loss: -247650.278\n",
      "Epoch[65/100] Loss: -261279.000\n",
      "Epoch[66/100] Loss: -256150.528\n",
      "Epoch[66/100] Loss: -243897.667\n",
      "Epoch[67/100] Loss: -259762.056\n",
      "Epoch[67/100] Loss: -239558.361\n",
      "Epoch[68/100] Loss: -282552.889\n",
      "Epoch[68/100] Loss: -260237.583\n",
      "Epoch[69/100] Loss: -217194.472\n",
      "Epoch[69/100] Loss: -251070.056\n",
      "Epoch[70/100] Loss: -225628.444\n",
      "Epoch[70/100] Loss: -232080.306\n",
      "Epoch[71/100] Loss: -221717.167\n",
      "Epoch[71/100] Loss: -212218.306\n",
      "Epoch[72/100] Loss: -258920.444\n",
      "Epoch[72/100] Loss: -238528.750\n",
      "Epoch[73/100] Loss: -235548.194\n",
      "Epoch[73/100] Loss: -337619.167\n",
      "Epoch[74/100] Loss: -228499.486\n",
      "Epoch[74/100] Loss: -251274.167\n",
      "Epoch[75/100] Loss: -235476.417\n",
      "Epoch[75/100] Loss: -212905.306\n",
      "Epoch[76/100] Loss: -236355.000\n",
      "Epoch[76/100] Loss: -238887.000\n",
      "Epoch[77/100] Loss: -223776.000\n",
      "Epoch[77/100] Loss: -270011.333\n",
      "Epoch[78/100] Loss: -277535.194\n",
      "Epoch[78/100] Loss: -257153.111\n",
      "Epoch[79/100] Loss: -251550.861\n",
      "Epoch[79/100] Loss: -267613.056\n",
      "Epoch[80/100] Loss: -228683.472\n",
      "Epoch[80/100] Loss: -194341.417\n",
      "Epoch[81/100] Loss: -219674.750\n",
      "Epoch[81/100] Loss: -253390.639\n",
      "Epoch[82/100] Loss: -228221.264\n",
      "Epoch[82/100] Loss: -246988.500\n",
      "Epoch[83/100] Loss: -232380.347\n",
      "Epoch[83/100] Loss: -223169.264\n",
      "Epoch[84/100] Loss: -241156.833\n",
      "Epoch[84/100] Loss: -247812.889\n",
      "Epoch[85/100] Loss: -223343.000\n",
      "Epoch[85/100] Loss: -257643.972\n",
      "Epoch[86/100] Loss: -262385.222\n",
      "Epoch[86/100] Loss: -243676.028\n",
      "Epoch[87/100] Loss: -237784.833\n",
      "Epoch[87/100] Loss: -241057.222\n",
      "Epoch[88/100] Loss: -260967.167\n",
      "Epoch[88/100] Loss: -275701.972\n",
      "Epoch[89/100] Loss: -242251.028\n",
      "Epoch[89/100] Loss: -256045.000\n",
      "Epoch[90/100] Loss: -269004.694\n",
      "Epoch[90/100] Loss: -250634.583\n",
      "Epoch[91/100] Loss: -267904.806\n",
      "Epoch[91/100] Loss: -223963.944\n",
      "Epoch[92/100] Loss: -240822.056\n",
      "Epoch[92/100] Loss: -210152.569\n",
      "Epoch[93/100] Loss: -249009.444\n",
      "Epoch[93/100] Loss: -232522.056\n",
      "Epoch[94/100] Loss: -292724.750\n",
      "Epoch[94/100] Loss: -220541.806\n",
      "Epoch[95/100] Loss: -222205.167\n",
      "Epoch[95/100] Loss: -261290.083\n",
      "Epoch[96/100] Loss: -247370.500\n",
      "Epoch[96/100] Loss: -224674.889\n",
      "Epoch[97/100] Loss: -235909.778\n",
      "Epoch[97/100] Loss: -209092.792\n",
      "Epoch[98/100] Loss: -218494.347\n",
      "Epoch[98/100] Loss: -201513.833\n",
      "Epoch[99/100] Loss: -206174.569\n",
      "Epoch[99/100] Loss: -230757.819\n",
      "Epoch[100/100] Loss: -225561.306\n",
      "Epoch[100/100] Loss: -254827.944\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiago/anaconda3/envs/density-lime3.7/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type VAE. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "path_model_cvae = '../models/mode_cvae.pth'\n",
    "torch.save(vae, path_model_cvae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (layers_encoder): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc_log_var): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc_out): Linear(in_features=512, out_features=2048, bias=True)\n",
       "  (layers_decoder): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "      (3): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(path_model_cvae)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
